{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from util.data import get_dl, get_train_ds, get_val_ds\n",
    "from util.training_utils import train, check_accuracy, save, load\n",
    "from models.Base3DUNet import Base3DUNet\n",
    "from util.loss import DiceLoss, BCEDiceLoss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "EPOCHS = 100\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "LR = 0.0001\n",
    "# DEVICE = 'cpu'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: 221, masks: 221 \n",
      "images: 148, masks: 148 \n"
     ]
    }
   ],
   "source": [
    "train_dl = get_dl(get_train_ds(), BATCH_SIZE,nw=2)\n",
    "val_dl = get_dl(get_val_ds(), BATCH_SIZE, nw=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "75"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base3DUNet(\n",
      "  (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (downs): ModuleList(\n",
      "    (0): DoubleConv3D(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv3d(3, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): DoubleConv3D(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): DoubleConv3D(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (4): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): DoubleConv3D(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (4): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ups): ModuleList(\n",
      "    (0): ConvTranspose3d(1024, 512, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (1): DoubleConv3D(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv3d(1024, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (4): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ConvTranspose3d(512, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (3): DoubleConv3D(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (4): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (4): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (5): DoubleConv3D(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (7): DoubleConv3D(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bottleneck): DoubleConv3D(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv3d(512, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (4): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (output_conv): Conv3d(64, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Base3DUNet(3, 3, features=[64, 128, 256, 512]).to(DEVICE)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# load(model, \"weights/3D/3d_50e_adam_b4_dice\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# model.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters = 90302147\n",
      "total learnable parameters = 90302147\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"total parameters = {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"total learnable parameters = {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "# loss = torch.nn.BCEWithLogitsLoss # cannot be used because there's a lot of imbalance anyway, so it is better to combine it with dice\n",
    "# loss = BCEDiceLoss()\n",
    "loss = DiceLoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(DEVICE)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "At epoch [1/100]: 100%|██████████| 56/56 [01:40<00:00,  1.80s/it, loss=0.909]\n",
      "At epoch [2/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.952]\n",
      "At epoch [3/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.878]\n",
      "At epoch [4/100]: 100%|██████████| 56/56 [01:37<00:00,  1.74s/it, loss=0.855]\n",
      "At epoch [5/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.898]\n",
      "At epoch [6/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.982]\n",
      "At epoch [7/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.849]\n",
      "At epoch [8/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.853]\n",
      "At epoch [9/100]: 100%|██████████| 56/56 [01:38<00:00,  1.76s/it, loss=0.809]\n",
      "At epoch [10/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.846]\n",
      "At epoch [11/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.838]\n",
      "At epoch [12/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.655]\n",
      "At epoch [13/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.759]\n",
      "At epoch [14/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.908]\n",
      "At epoch [15/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.863]\n",
      "At epoch [16/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.635]\n",
      "At epoch [17/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.589]\n",
      "At epoch [18/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.812]\n",
      "At epoch [19/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.373]\n",
      "At epoch [20/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.553]\n",
      "At epoch [21/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.342]\n",
      "At epoch [22/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.541]\n",
      "At epoch [23/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.326]\n",
      "At epoch [24/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.249]\n",
      "At epoch [25/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.456]\n",
      "At epoch [26/100]: 100%|██████████| 56/56 [01:42<00:00,  1.83s/it, loss=0.354]\n",
      "At epoch [27/100]: 100%|██████████| 56/56 [01:38<00:00,  1.76s/it, loss=0.614]\n",
      "At epoch [28/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.313]\n",
      "At epoch [29/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.266]\n",
      "At epoch [30/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.436]\n",
      "At epoch [31/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.193]\n",
      "At epoch [32/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.665]\n",
      "At epoch [33/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.165]\n",
      "At epoch [34/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.203]\n",
      "At epoch [35/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.272]\n",
      "At epoch [36/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.141]\n",
      "At epoch [37/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.328]\n",
      "At epoch [38/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.115]\n",
      "At epoch [39/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.28] \n",
      "At epoch [40/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.194]\n",
      "At epoch [41/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.214]\n",
      "At epoch [42/100]: 100%|██████████| 56/56 [01:37<00:00,  1.74s/it, loss=0.248]\n",
      "At epoch [43/100]: 100%|██████████| 56/56 [01:37<00:00,  1.74s/it, loss=0.217]\n",
      "At epoch [44/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.17] \n",
      "At epoch [45/100]: 100%|██████████| 56/56 [01:37<00:00,  1.74s/it, loss=0.167]\n",
      "At epoch [46/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.202]\n",
      "At epoch [47/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.277]\n",
      "At epoch [48/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.233]\n",
      "At epoch [49/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.403]\n",
      "At epoch [50/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.265]\n",
      "At epoch [51/100]: 100%|██████████| 56/56 [01:37<00:00,  1.74s/it, loss=0.15] \n",
      "At epoch [52/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.17]  \n",
      "At epoch [53/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.253]\n",
      "At epoch [54/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.181]\n",
      "At epoch [55/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.125]\n",
      "At epoch [56/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.0956]\n",
      "At epoch [57/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.14] \n",
      "At epoch [58/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.17] \n",
      "At epoch [59/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.0629]\n",
      "At epoch [60/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.419] \n",
      "At epoch [61/100]: 100%|██████████| 56/56 [01:37<00:00,  1.74s/it, loss=0.197]\n",
      "At epoch [62/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.164]\n",
      "At epoch [63/100]: 100%|██████████| 56/56 [01:38<00:00,  1.76s/it, loss=0.156] \n",
      "At epoch [64/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.254] \n",
      "At epoch [65/100]: 100%|██████████| 56/56 [01:37<00:00,  1.75s/it, loss=0.0596]\n",
      "At epoch [66/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.29]  \n",
      "At epoch [67/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.254] \n",
      "At epoch [68/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.0981]\n",
      "At epoch [69/100]: 100%|██████████| 56/56 [01:38<00:00,  1.75s/it, loss=0.07]  \n",
      "At epoch [70/100]:  39%|███▉      | 22/56 [00:40<00:58,  1.72s/it, loss=0.114] "
     ]
    }
   ],
   "source": [
    "train(model, epochs=EPOCHS, training_loader=train_dl, loss_fn=loss, device=DEVICE, optimizer=opt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_accuracy(val_dl,model,DEVICE)\n",
    "# convT\n",
    "# 100 DICE Results: Results: 115510440/116391936 with accuracy 99.2427 Dice score: 0.7560997009277344\n",
    "# 100 BCE-DICE Results: 115626234/116391936 with accuracy 99.3421 Dice score: 0.7765376567840576\n",
    "# upsample\n",
    "# 100 DICE Results: Results: 115510440/116391936 with accuracy A Dice score: D\n",
    "# 100 BCE-DICE Results: 115626234/116391936 with accuracy A Dice score: D"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved the model...\n"
     ]
    }
   ],
   "source": [
    "# saving sample\n",
    "save(model,\"weights/3D/3d_100e_adam_b4_bce-dice\")\n",
    "print(\"saved the model...\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "At epoch [1/50]: 100%|██████████| 56/56 [01:36<00:00,  1.73s/it, loss=0.201] \n",
      "At epoch [2/50]: 100%|██████████| 56/56 [01:37<00:00,  1.74s/it, loss=0.118]\n",
      "At epoch [3/50]: 100%|██████████| 56/56 [01:37<00:00,  1.74s/it, loss=0.171] \n",
      "At epoch [4/50]: 100%|██████████| 56/56 [01:37<00:00,  1.74s/it, loss=0.188]\n",
      "At epoch [5/50]: 100%|██████████| 56/56 [01:37<00:00,  1.74s/it, loss=0.135]\n",
      "At epoch [6/50]: 100%|██████████| 56/56 [01:37<00:00,  1.74s/it, loss=0.0845]\n",
      "At epoch [7/50]: 100%|██████████| 56/56 [01:37<00:00,  1.74s/it, loss=0.27]  \n",
      "At epoch [8/50]: 100%|██████████| 56/56 [01:37<00:00,  1.74s/it, loss=0.218] \n",
      "At epoch [9/50]: 100%|██████████| 56/56 [01:37<00:00,  1.74s/it, loss=0.225] \n",
      "At epoch [10/50]:  12%|█▎        | 7/56 [00:14<01:28,  1.81s/it, loss=0.128]"
     ]
    }
   ],
   "source": [
    "train(model, epochs=EPOCHS, training_loader=train_dl, loss_fn=loss, device=DEVICE, optimizer=opt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "check_accuracy(val_dl,model,DEVICE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# loading sample\n",
    "model1 = Base3DUNet(3,3)\n",
    "load(model,\"weights/3D/t1\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
