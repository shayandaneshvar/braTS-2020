{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cbaqaUgSbP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80beb762-47e3-4dea-e38e-65711a419b7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/ProjectDL/BraTS/train/images\n"
          ]
        }
      ],
      "source": [
        "from glob import glob\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "\n",
        "# clean ds\n",
        "CLEAN_DS_PATH = '/content/gdrive/MyDrive/ProjectDL/BraTS'\n",
        "\n",
        "# train\n",
        "CLEAN_TRAIN_PATH = f'{CLEAN_DS_PATH}/train'\n",
        "CLEAN_TRAIN_IMG_PATH = f'{CLEAN_TRAIN_PATH}/images'\n",
        "CLEAN_TRAIN_MSK_PATH = f'{CLEAN_TRAIN_PATH}/masks'\n",
        "print(CLEAN_TRAIN_IMG_PATH)\n",
        "# val\n",
        "CLEAN_VAL_PATH = f'{CLEAN_DS_PATH}/val'\n",
        "CLEAN_VAL_IMG_PATH = f'{CLEAN_VAL_PATH}/images'\n",
        "CLEAN_VAL_MSK_PATH = f'{CLEAN_VAL_PATH}/masks'\n",
        "\n",
        "\n",
        "# MAking dataset ready\n",
        "class SimpleLogger:\n",
        "\n",
        "    def __init__(self, debug=True):\n",
        "        self.debug = debug\n",
        "\n",
        "    def enable_debug(self):\n",
        "        self.debug = True\n",
        "\n",
        "    def disable_debug(self):\n",
        "        self.debug = False\n",
        "\n",
        "    def log(self, message, condition=True):\n",
        "        if self.debug and condition:\n",
        "            print(message)\n",
        "\n",
        "\n",
        "logger = SimpleLogger(debug=True)\n",
        "\n",
        "def to_categorical(y, n_classes):\n",
        "    return np.eye(n_classes, dtype=\"uint8\")[y]\n",
        "\n",
        "\n",
        "class BraTSDataset(Dataset):\n",
        "    def log(self, message):\n",
        "        logger.log(message, condition=self.debug)\n",
        "\n",
        "    def __init__(self, images_path, masks_path, transform=None, one_hot_target=True, debug=True):\n",
        "        \n",
        "        # data_files_images = sorted(os.listdir(images_path))\n",
        "        # self.images = []\n",
        "        # for file in data_files_images:\n",
        "        #   if file.endswith('.npy'):\n",
        "        #     file_path_images = os.path.join(images_path, file)\n",
        "        #     image = np.load(file_path_images)\n",
        "        #     self.images.append(image)\n",
        "\n",
        "        # data_files_masks = sorted(os.listdir(masks_path))\n",
        "        # self.masks = []\n",
        "        # for file in data_files_masks:\n",
        "        #   if file.endswith('.npy'):\n",
        "        #     file_path_masks = os.path.join(masks_path, file)\n",
        "        #     mask = np.load(file_path_masks)\n",
        "        #     self.masks.append(mask)\n",
        "              \n",
        "        self.images = sorted(glob(f\"{images_path}/*.npy\"))\n",
        "        self.masks = sorted(glob(f\"{masks_path}/*.npy\"))\n",
        "        self.transform = transform\n",
        "        self.one_hot_target = one_hot_target\n",
        "        self.debug = debug\n",
        "        self.log(f\"images: {len(self.images)}, masks: {len(self.masks)} \")\n",
        "        assert len(self.images) == len(self.masks), \"images and masks lengths are not the same!\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # if torch.is_tensor(idx):\n",
        "        #     idx = idx.tolist()\n",
        "\n",
        "        image = np.load(self.images[idx])\n",
        "        mask = np.load(self.masks[idx])\n",
        "        # resizing image and mask, experimental\n",
        "        image = image[::2,::2,::2]\n",
        "        mask = mask[::2,::2,::2]\n",
        "        if self.one_hot_target:\n",
        "            mask = to_categorical(mask, 4)\n",
        "            mask = mask[::, ::, ::, 1::]  # discard background\n",
        "\n",
        "        image = torch.from_numpy(image).float()  # .double()\n",
        "        mask = torch.from_numpy(mask)  # .float() #.long()\n",
        "\n",
        "        return image.permute((3, 0, 1, 2)), mask.permute((3, 0, 1, 2))\n",
        "\n",
        "\n",
        "def get_dl(dataset, batch_size=4, pm=True, nw=1):\n",
        "    return DataLoader(dataset, batch_size, shuffle=True, pin_memory=pm, num_workers=nw, )\n",
        "\n",
        "def get_train_ds():\n",
        "    return BraTSDataset(CLEAN_TRAIN_IMG_PATH, CLEAN_TRAIN_MSK_PATH)\n",
        "\n",
        "\n",
        "def get_val_ds():\n",
        "    return BraTSDataset(CLEAN_VAL_IMG_PATH, CLEAN_VAL_MSK_PATH)\n",
        "\n",
        "# this is for testing only\n",
        "# if __name__ == '__main__':\n",
        "#     train_ds = BraTSDataset(CLEAN_TRAIN_IMG_PATH, CLEAN_TRAIN_MSK_PATH)\n",
        "#     print(train_ds[0][0].shape)\n",
        "#     print(train_ds[0][1].shape)\n",
        "#     dl = get_dl(train_ds, batch_size=1)\n",
        "#     print(\"OK\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Residual 3DUNet model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        # the output image will be (n + 2p — f + 1) * (n + 2p — f + 1) where p =1 in this case.\n",
        "        # Convolutional Layer\n",
        "        self.conv = nn.Sequential(\n",
        "          nn.BatchNorm3d(in_channels),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride),\n",
        "          nn.BatchNorm3d(out_channels),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1, stride=1))\n",
        "\n",
        "        # Identity Mapping\n",
        "        self.shortcut = nn.Conv3d(in_channels, out_channels, kernel_size=1, padding=0, stride=stride)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv(inputs) \n",
        "        s = self.shortcut(inputs)       \n",
        "        skip = x + s\n",
        "        return skip\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode=\"trilinear\", align_corners=True) #  mode=\"trilinear\"\n",
        "        self.residual = ResidualBlock(in_channels + out_channels, out_channels)\n",
        "\n",
        "    def forward(self, inputs, skip):\n",
        "        x = self.upsample(inputs)\n",
        "        x = torch.cat([x, skip], axis=1)\n",
        "        x = self.residual(x)\n",
        "        return x\n",
        "\n",
        "class Res3DUNet(nn.Module):\n",
        "    # the default dataset has 3 channels of data ->  T1CE, T2, FLAIR\n",
        "    # The output has background, NCR/NET, ED, ET \n",
        "\n",
        "    def __init__(self, in_channels=3, out_channels=4):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder 1 \n",
        "        self.conv1 = nn.Conv3d(in_channels, 64, kernel_size=3, padding=1)\n",
        "        self.bn1   = nn.BatchNorm3d(64)\n",
        "        self.relu  = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n",
        "        #Identity Mapping\n",
        "        self.conv3 = nn.Conv3d(in_channels, 64, kernel_size=1, padding=0)\n",
        "        \n",
        "        # Encoder 2 \n",
        "        self.r2 = ResidualBlock(64, 128, stride=2)\n",
        "        # Encoder 3 \n",
        "        self.r3 = ResidualBlock(128, 256, stride=2)\n",
        "        # Encoder 4 \n",
        "        self.r4 = ResidualBlock(256, 512, stride=2)\n",
        "        # Bridge\n",
        "        self.r5 = ResidualBlock(512, 1024, stride=2)\n",
        "        # Decoder 1\n",
        "        self.d1 = DecoderBlock(1024, 512)\n",
        "        # Decoder 2\n",
        "        self.d2 = DecoderBlock(512, 256)\n",
        "        # Decoder 3\n",
        "        self.d3 = DecoderBlock(256, 128)\n",
        "        # Decoder 4\n",
        "        self.d4 = DecoderBlock(128, 64)\n",
        "\n",
        "        # Output \n",
        "        self.output = nn.Conv3d(64, out_channels, kernel_size=1, padding=0)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Encoder 1 \n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        s = self.conv3(inputs)\n",
        "        skip1 = x + s\n",
        "        # Encoder 2 \n",
        "        skip2 = self.r2(skip1)\n",
        "        # Encoder 3 \n",
        "        skip3 = self.r3(skip2)\n",
        "        # Encoder 4 \n",
        "        skip4 = self.r4(skip3)\n",
        "        # Bridge \n",
        "        b = self.r5(skip4)\n",
        "        # Decoder 1\n",
        "        d1 = self.d1(b, skip4)\n",
        "        # Decoder 2\n",
        "        d2 = self.d2(d1, skip3)\n",
        "        # Decoder 3\n",
        "        d3 = self.d3(d2, skip2)\n",
        "        # Decoder 4\n",
        "        d4 = self.d4(d3, skip1)\n",
        "        # output \n",
        "        output = self.output(d4)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "# def _test_Res3dUNet():\n",
        "#     x = torch.randn((1, 3, 128, 128, 128)).to(device)\n",
        "#     print(x.shape)\n",
        "#     model = Res3DUNet(in_channels=3).to(device)\n",
        "#     out = model(x)\n",
        "#     print(out.shape)\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     _test_Res3dUNet()\n",
        "\n",
        "\n",
        "\n",
        "# class DoubleConv3D(nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super().__init__()\n",
        "#         # 1 + (L - l + 2P)/s\n",
        "#         self.conv = nn.Sequential(\n",
        "#             # 1 + out - 3 + 2 = out\n",
        "#             nn.Conv3d(in_channels, out_channels, 3, stride=1, padding=1, bias=False),\n",
        "#             nn.BatchNorm3d(out_channels),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv3d(out_channels, out_channels, 3, stride=1, padding=1, bias=False),\n",
        "#             nn.BatchNorm3d(out_channels),\n",
        "#             nn.ReLU(inplace=True)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, inputs):\n",
        "#         return self.conv(inputs)\n",
        "\n",
        "\n",
        "# class Base3DUNet(nn.Module):\n",
        "#     # the default dataset has 3 channels of data ->  T1CE, T2, FLAIR\n",
        "#     # The output has background, NCR/NET, ED, ET\n",
        "#     def __init__(self, in_channels=3, out_channels=4, features=[64, 128, 256, 512]):\n",
        "#         super().__init__()\n",
        "#         # 1 + (L - l + 2P)/s\n",
        "#         # 1 + (L - 2)/2 = L\n",
        "#         self.pooling = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "#         self.downs = nn.ModuleList()\n",
        "#         self.ups = nn.ModuleList()\n",
        "\n",
        "#         # Each Layer - number of filters , see UNet architecture\n",
        "#         input_channels = in_channels\n",
        "\n",
        "#         for feature in features:\n",
        "#             self.downs.append(DoubleConv3D(input_channels, feature))\n",
        "#             input_channels = feature\n",
        "\n",
        "#         for feature in reversed(features):\n",
        "#             self.ups.append(nn.ConvTranspose3d(feature * 2, feature, kernel_size=2, stride=2))\n",
        "#             self.ups.append(DoubleConv3D(feature * 2, feature))\n",
        "\n",
        "#         self.bottleneck = DoubleConv3D(features[-1], features[-1] * 2)  # this connects downs to ups\n",
        "\n",
        "#         self.output_conv = nn.Conv3d(features[0], out_channels, kernel_size=1)  # last layer - feature compression\n",
        "\n",
        "#     def forward(self, inputs):\n",
        "#         skips = []\n",
        "\n",
        "#         x = inputs\n",
        "#         for down in self.downs:\n",
        "#             x = down(x)\n",
        "#             skips.append(x)\n",
        "#             x = self.pooling(x)\n",
        "\n",
        "#         x = self.bottleneck(x)\n",
        "\n",
        "#         for idx in range(0, len(self.ups), 2):  # going up 2 steps, as each step has convTranspose and DoubleConv\n",
        "#             x = self.ups[idx](x)  # up sampling w/ the convTranspose\n",
        "#             skip_connection = skips.pop()  # give me the last skip I added, to add it first on the ups\n",
        "#             x = torch.cat((skip_connection, x), dim=1)  # dim 0 is batch, dim 1 is the channels\n",
        "#             x = self.ups[idx + 1](x)  # double conv\n",
        "\n",
        "#         return self.output_conv(x)"
      ],
      "metadata": {
        "id": "KneK3wtBdjB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Functions\n",
        "# DSC = 2 * |A intersect B| / (|A| + |B|)\n",
        "class DiceLoss(nn.Module):\n",
        "    \"\"\"Calculate dice loss.\"\"\"\n",
        "\n",
        "    def __init__(self, eps: float = 1e-9):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self,\n",
        "                logits: torch.Tensor,\n",
        "                targets: torch.Tensor) -> torch.Tensor:\n",
        "        num = targets.size(0)\n",
        "        probability = torch.sigmoid(logits)\n",
        "        probability = probability.view(num, -1)\n",
        "        targets = targets.view(num, -1)\n",
        "        assert (probability.shape == targets.shape)\n",
        "\n",
        "        intersection = 2.0 * (probability * targets).sum()\n",
        "        union = probability.sum() + targets.sum()\n",
        "        dice_score = (intersection + self.eps) / union\n",
        "        # print(\"intersection\", intersection, union, dice_score)\n",
        "        return 1.0 - dice_score\n",
        "\n",
        "\n",
        "class BCEDiceLoss(nn.Module):\n",
        "    \"\"\"Compute objective loss: BCE loss + DICE loss.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BCEDiceLoss, self).__init__()\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "        self.dice = DiceLoss()\n",
        "\n",
        "    def forward(self,\n",
        "                logits: torch.Tensor,\n",
        "                targets: torch.Tensor) -> torch.Tensor:\n",
        "        assert (logits.shape == targets.shape)\n",
        "        dice_loss = self.dice(logits, targets)\n",
        "        bce_loss = self.bce(logits, targets)\n",
        "\n",
        "        return dice_loss # bce_loss + dice_loss"
      ],
      "metadata": {
        "id": "S2yv0Y5ceqpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All the previous cells should run first\n",
        "# Training Residual Unet \n",
        "\n",
        "# Hyper Parameters\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 100\n",
        "LR = 0.0001\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_dl = get_dl(get_train_ds(), BATCH_SIZE,nw=1)\n",
        "\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "model = Res3DUNet(3, 3).to(DEVICE)\n",
        "# model = Base3DUNet(3, 3, features=[64, 128, 256, 512]).to(DEVICE)\n",
        "# print(model)\n",
        "\n",
        "print(f\"total parameters = {sum(p.numel() for p in model.parameters())}\")\n",
        "print(f\"total learnable parameters = {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
        "\n",
        "# loss functons\n",
        "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "loss = BCEDiceLoss()\n",
        "#loss = DiceLoss()\n",
        "\n",
        "\n",
        "def train(model, epochs=1, training_loader=None, loss_fn=None, device=None,\n",
        "          optimizer: torch.optim.Optimizer = None):\n",
        "    for epoch in range(epochs):\n",
        "        tq_dl = tqdm(training_loader)\n",
        "        for idx, (image, mask) in enumerate(tq_dl):\n",
        "            image, mask = image.to(device), mask.to(device)\n",
        "            # forward pass\n",
        "            out = model(image)\n",
        "            loss = loss_fn(out, mask.float())\n",
        "            # backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # optimize\n",
        "            optimizer.step()\n",
        "\n",
        "            tq_dl.set_description(f\"At epoch [{epoch + 1}/{epochs}]\")\n",
        "            tq_dl.set_postfix(loss=loss.item())  # acc, ...\n",
        "\n",
        "# do not give in the format - the format will be .pt\n",
        "def save(model, path):\n",
        "    torch.save(model.state_dict(), f\"{path}.pt\")\n",
        "\n",
        "\n",
        "# training \n",
        "EPOCHS = 100\n",
        "train(model, epochs=EPOCHS, training_loader=train_dl, loss_fn=loss, device=DEVICE, optimizer=opt)\n",
        "\n",
        "# saving sample\n",
        "save(model,\"/content/gdrive/MyDrive/ProjectDL/BraTS/3d_100e_adam_dice\")\n",
        "print(\"saved the model...\")\n"
      ],
      "metadata": {
        "id": "Ta8ZkP5Ne10Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08722a1c-f2a7-4f76-eaa6-300dbd950ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images: 221, masks: 221 \n",
            "total parameters = 95882563\n",
            "total learnable parameters = 95882563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "At epoch [1/100]: 100%|██████████| 56/56 [04:15<00:00,  4.57s/it, loss=0.788]\n",
            "At epoch [2/100]: 100%|██████████| 56/56 [02:12<00:00,  2.37s/it, loss=0.535]\n",
            "At epoch [3/100]: 100%|██████████| 56/56 [02:08<00:00,  2.29s/it, loss=0.321]\n",
            "At epoch [4/100]: 100%|██████████| 56/56 [02:10<00:00,  2.34s/it, loss=0.323]\n",
            "At epoch [5/100]: 100%|██████████| 56/56 [02:08<00:00,  2.29s/it, loss=0.607]\n",
            "At epoch [6/100]: 100%|██████████| 56/56 [02:11<00:00,  2.35s/it, loss=0.567]\n",
            "At epoch [7/100]: 100%|██████████| 56/56 [02:08<00:00,  2.30s/it, loss=0.766]\n",
            "At epoch [8/100]: 100%|██████████| 56/56 [02:11<00:00,  2.35s/it, loss=0.275]\n",
            "At epoch [9/100]: 100%|██████████| 56/56 [02:14<00:00,  2.39s/it, loss=0.319]\n",
            "At epoch [10/100]: 100%|██████████| 56/56 [02:11<00:00,  2.35s/it, loss=0.258]\n",
            "At epoch [11/100]: 100%|██████████| 56/56 [02:09<00:00,  2.31s/it, loss=0.559]\n",
            "At epoch [12/100]: 100%|██████████| 56/56 [02:10<00:00,  2.32s/it, loss=0.663]\n",
            "At epoch [13/100]: 100%|██████████| 56/56 [02:08<00:00,  2.30s/it, loss=0.515]\n",
            "At epoch [14/100]: 100%|██████████| 56/56 [02:10<00:00,  2.33s/it, loss=0.383]\n",
            "At epoch [15/100]: 100%|██████████| 56/56 [02:10<00:00,  2.34s/it, loss=0.474]\n",
            "At epoch [16/100]: 100%|██████████| 56/56 [02:11<00:00,  2.35s/it, loss=0.216]\n",
            "At epoch [17/100]: 100%|██████████| 56/56 [02:10<00:00,  2.32s/it, loss=0.284]\n",
            "At epoch [18/100]: 100%|██████████| 56/56 [02:10<00:00,  2.34s/it, loss=0.443]\n",
            "At epoch [19/100]: 100%|██████████| 56/56 [02:11<00:00,  2.35s/it, loss=0.623]\n",
            "At epoch [20/100]: 100%|██████████| 56/56 [02:10<00:00,  2.33s/it, loss=0.332]\n",
            "At epoch [21/100]: 100%|██████████| 56/56 [02:11<00:00,  2.35s/it, loss=0.47]\n",
            "At epoch [22/100]: 100%|██████████| 56/56 [02:14<00:00,  2.40s/it, loss=0.379]\n",
            "At epoch [23/100]: 100%|██████████| 56/56 [02:10<00:00,  2.33s/it, loss=0.167]\n",
            "At epoch [24/100]: 100%|██████████| 56/56 [02:11<00:00,  2.36s/it, loss=0.394]\n",
            "At epoch [25/100]: 100%|██████████| 56/56 [02:10<00:00,  2.33s/it, loss=0.206]\n",
            "At epoch [26/100]: 100%|██████████| 56/56 [02:09<00:00,  2.31s/it, loss=0.286]\n",
            "At epoch [27/100]: 100%|██████████| 56/56 [02:11<00:00,  2.35s/it, loss=0.364]\n",
            "At epoch [28/100]: 100%|██████████| 56/56 [02:16<00:00,  2.45s/it, loss=0.262]\n",
            "At epoch [29/100]: 100%|██████████| 56/56 [02:09<00:00,  2.32s/it, loss=0.29]\n",
            "At epoch [30/100]: 100%|██████████| 56/56 [02:08<00:00,  2.29s/it, loss=0.239]\n",
            "At epoch [31/100]: 100%|██████████| 56/56 [02:13<00:00,  2.39s/it, loss=0.326]\n",
            "At epoch [32/100]: 100%|██████████| 56/56 [02:08<00:00,  2.29s/it, loss=0.136]\n",
            "At epoch [33/100]: 100%|██████████| 56/56 [02:08<00:00,  2.30s/it, loss=0.0985]\n",
            "At epoch [34/100]: 100%|██████████| 56/56 [02:10<00:00,  2.33s/it, loss=0.156]\n",
            "At epoch [35/100]: 100%|██████████| 56/56 [02:09<00:00,  2.31s/it, loss=0.522]\n",
            "At epoch [36/100]: 100%|██████████| 56/56 [02:10<00:00,  2.33s/it, loss=0.395]\n",
            "At epoch [37/100]: 100%|██████████| 56/56 [02:14<00:00,  2.39s/it, loss=0.612]\n",
            "At epoch [38/100]: 100%|██████████| 56/56 [02:10<00:00,  2.34s/it, loss=0.237]\n",
            "At epoch [39/100]: 100%|██████████| 56/56 [02:08<00:00,  2.30s/it, loss=0.366]\n",
            "At epoch [40/100]: 100%|██████████| 56/56 [02:07<00:00,  2.27s/it, loss=0.18]\n",
            "At epoch [41/100]: 100%|██████████| 56/56 [02:11<00:00,  2.35s/it, loss=0.224]\n",
            "At epoch [42/100]: 100%|██████████| 56/56 [02:11<00:00,  2.35s/it, loss=0.157]\n",
            "At epoch [43/100]: 100%|██████████| 56/56 [02:13<00:00,  2.38s/it, loss=0.289]\n",
            "At epoch [44/100]: 100%|██████████| 56/56 [02:08<00:00,  2.29s/it, loss=0.235]\n",
            "At epoch [45/100]: 100%|██████████| 56/56 [02:08<00:00,  2.30s/it, loss=0.262]\n",
            "At epoch [46/100]: 100%|██████████| 56/56 [02:07<00:00,  2.28s/it, loss=0.276]\n",
            "At epoch [47/100]: 100%|██████████| 56/56 [02:09<00:00,  2.32s/it, loss=0.467]\n",
            "At epoch [48/100]: 100%|██████████| 56/56 [02:09<00:00,  2.32s/it, loss=0.29]\n",
            "At epoch [49/100]: 100%|██████████| 56/56 [02:08<00:00,  2.30s/it, loss=0.22]\n",
            "At epoch [50/100]: 100%|██████████| 56/56 [02:07<00:00,  2.27s/it, loss=0.279]\n",
            "At epoch [51/100]: 100%|██████████| 56/56 [02:11<00:00,  2.35s/it, loss=0.144]\n",
            "At epoch [52/100]:  41%|████      | 23/56 [00:54<01:15,  2.28s/it, loss=0.184]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Validation\n",
        "# # Run the first two cell first \n",
        "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# # do not give in the format - the format will be .pt\n",
        "# def load(model, path, eval=True):\n",
        "#     model.load_state_dict(torch.load(f\"{path}.pt\"))\n",
        "#     if eval:\n",
        "#         model.eval()\n",
        "\n",
        "\n",
        "# def check_accuracy(data_loader, model, device=\"cuda\"):\n",
        "#     num_correct = 0\n",
        "#     num_pixels = 0\n",
        "#     dice_score = 0\n",
        "#     model.eval()\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for x, y in data_loader:\n",
        "#             x = x.to(device)\n",
        "#             y = y.to(device) #.unsqueeze(1)\n",
        "#             preds = torch.sigmoid(model(x))\n",
        "#             preds = (preds > 0.5).float()\n",
        "#             num_correct += (preds == y).sum()\n",
        "#             num_pixels += torch.numel(preds)\n",
        "#             dice_score += (2 * (preds * y).sum()) / (\n",
        "#                     (preds + y).sum() + 1e-8\n",
        "#             )\n",
        "\n",
        "#     print(\n",
        "#         f\"Results: {num_correct}/{num_pixels} with accuracy {num_correct / num_pixels * 100:.4f}\"\n",
        "#     )\n",
        "#     print(f\"Dice score: {dice_score / len(data_loader)}\")\n",
        "#     model.train()\n",
        "\n",
        "# BATCH_SIZE = 4;\n",
        "# # loading sample\n",
        "# val_dl = get_dl(get_val_ds(), BATCH_SIZE, nw=1)\n",
        "\n",
        "# # Loading model\n",
        "# model = Res3DUNet(3, 3).to(DEVICE)\n",
        "# load(model,\"/content/gdrive/MyDrive/ProjectDL/BraTS/3d_100e_adam_dice\")\n",
        "\n",
        "# check_accuracy(val_dl,model,DEVICE)\n",
        "# #BaseUNET\n",
        "# # 50 DICE Results: 115540617/116391936 with accuracy 99.2686 Dice score: 0.7475918531417847\n",
        "# # 100 DICE Results: Results: 115510440/116391936 with accuracy 99.2427 Dice score: 0.7560997009277344\n",
        "# # 100 BCE-DICE Results: 115626234/116391936 with accuracy 99.3421 Dice score: 0.7765376567840576\n",
        "\n",
        "# #ResUNET\n",
        "# # 100 BCE-DICE Results: Results: 115570441/116391936 with accuracy 99.2942 Dice score: 0.7470014691352844\n",
        "# # 100 DICE Results: 115284011/116391936 with accuracy 99.0481 Dice score: 0.6380645036697388"
      ],
      "metadata": {
        "id": "UHSeso7ii_d1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}